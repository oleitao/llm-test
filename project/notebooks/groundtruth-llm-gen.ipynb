{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"../data/fabrizioromano_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = tweets_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_count': 1,\n",
       " 'tweet_id': 1832563499995725843,\n",
       " 'username': 'Fabrizio Romano',\n",
       " 'text': '‚è≥üá≥üá± Memphis Depay, in attendance for Dutch national team game ahead of the formal steps to complete his Corinthians free transfer‚Ä¶\\n\\n‚Ä¶almost there. üèÅüáßüá∑ https://t.co/khXJknhl4L',\n",
       " 'created at': 'Sat Sep 07 23:36:00 +0000 2024',\n",
       " 'url': 'https://twitter.com/FabrizioRomano/status/1832563499995725843'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(model=\"llama3\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tweets_json.json', 'wt') as f_out:\n",
    "    json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a football fan who wants to get football news from the tweets of a Journalist.\n",
    "A tweet would be provided, you are to formulate 3 questions this fan might ask based on the tweet. \n",
    "The questions are to illustrate a fan asking a question that this tweet will answer, \n",
    "So each questions should not use pronouns that refer to people or things that are not named or stated in the question.\n",
    "I repeat, no pronouns. Each question should state the names of who or what you are referring to from the tweet.\n",
    "Each question should be a standalone, and not a followup to past questions.\n",
    "No question should reference another question or names from a previous question. Each question is a standalone and not dependent on other generated questions.\n",
    "The questions should be complete, short, and consise.\n",
    "for context, The questions would be used to create a ground truth dataset.\n",
    "\n",
    "\n",
    "The tweet:\n",
    "{tweet} \n",
    "\n",
    " Instruction:\n",
    "Provide the output as a list without using code blocks but the quwstions should be in quotes separated by a comma. \n",
    "The format should be, first question in quotes then a comma, second question in quotes then a comma, third question in quotes, that's all, no extra character.\n",
    "Please do not include any extra text or characters in your response. Just follow the format I stated.\n",
    "Format:\n",
    "\n",
    "\n",
    "\"question1\", \"question2\", \"question3\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You emulate a football fan who wants to get football news from the tweets of a Journalist.\\nA tweet would be provided, you are to formulate 3 questions this fan might ask based on the tweet. \\nThe questions are to illustrate a fan asking a question that this tweet will answer, \\nSo each questions should not use pronouns that refer to people or things that are not named or stated in the question.\\nI repeat, no pronouns. Each question should state the names of who or what you are referring to from the tweet.\\nEach question should be a standalone, and not a followup to past questions.\\nNo question should reference another question or names from a previous question. Each question is a standalone and not dependent on other generated questions.\\nThe questions should be complete, short, and consise. \\n\\n\\nThe tweet:\\n‚ú®üá©üá™ Three assists, one goal tonight for Jamal Musiala.\\n\\nKimmich: ‚ÄúI don\\'t know what criteria are used to decide the Ballon d‚ÄôOr list‚Äù.\\n\\n‚ÄúThe best players should actually be on this list. And Jamal is definitely one of them‚Äù.\\n\\n‚ÄúHe showed that again today‚Äù, says via @kerry_hau. https://t.co/nRXXg9UuR6 \\n\\n Instruction:\\nProvide the output as a list without using code blocks but the quwstions should be in quotes separated by a comma. \\nThe format should be, first question in quotes then a comma, second question in quotes then a comma, third question in quotes, that\\'s all, no extra character.\\nPlease do not include any extra text or characters in your response. Just follow the format I stated.\\nFormat:\\n\\n\\n\"question1\", \"question2\", \"question3\"'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt = prompt_template.format(tweet=documents[2]['text'])\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Who gave three assists and one goal tonight?\", \"What are Kimmich's thoughts on the Ballon d'Or list?\", \"Is Jamal Musiala considered one of the best players?\"\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(formatted_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [1:31:52<00:00, 55.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for doc in tqdm(documents[:100]):  \n",
    "    formatted_prompt = prompt_template.format(tweet=doc['text'])\n",
    "    result = model.invoke(formatted_prompt)\n",
    "    questions = [q.strip().strip('\"') for q in result.split(',')]\n",
    "    document = {\"id\": doc['tweet_id'], \"questions\": questions}\n",
    "    ground_truth.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [2:41:18<00:00, 48.64s/it]  \n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents[101:300]):  \n",
    "    formatted_prompt = prompt_template.format(tweet=doc['text'])\n",
    "    result = model.invoke(formatted_prompt)\n",
    "    questions = [q.strip().strip('\"') for q in result.split(',')]\n",
    "    document = {\"id\": doc['tweet_id'], \"questions\": questions}\n",
    "    ground_truth.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "ground_truth_copy = copy.deepcopy(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_doc in ground_truth_copy:\n",
    "    matching_doc = next((doc for doc in documents if doc['tweet_id'] == gt_doc['id']), None)\n",
    "    if matching_doc:\n",
    "        gt_doc['tweet_text'] = matching_doc['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as ../data/ground_truth_copy.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = '../data/ground_truth_copy.json'\n",
    "\n",
    "with open(json_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(ground_truth_copy, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "ground_truth_data = []\n",
    "\n",
    "for doc in ground_truth_copy:\n",
    "    tweet_id = doc['id']  \n",
    "    \n",
    "    for question in doc['questions']:\n",
    "        ground_truth_data.append({\"question\": question, \"tweet_id\": tweet_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as ../data/ground_truth_data.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = '../data/ground_truth_data.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"question\", \"tweet_id\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(ground_truth_data)\n",
    "\n",
    "print(f\"CSV file saved as {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_frequent_tweet_ids(csv_file):\n",
    "    # Dictionary to count occurrences of tweet_ids\n",
    "    tweet_id_count = defaultdict(int)\n",
    "\n",
    "    # Open and read the CSV file\n",
    "    with open(csv_file, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Loop over each row and count occurrences of tweet_id\n",
    "        for row in reader:\n",
    "            tweet_id = row['tweet_id']\n",
    "            tweet_id_count[tweet_id] += 1\n",
    "\n",
    "    # Sort out tweet_ids that appear more than 3 times\n",
    "    frequent_tweet_ids = [tweet_id for tweet_id, count in tweet_id_count.items() if count > 3]\n",
    "    \n",
    "    return frequent_tweet_ids\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = '../data/ground_truth_data.csv'  # Replace with your actual CSV file path\n",
    "frequent_ids = get_frequent_tweet_ids(csv_file_path)\n",
    "print(frequent_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
